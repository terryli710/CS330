{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CS330_Homework1_Stencil.ipynb","provenance":[{"file_id":"1slBqgKa20iTatoWThMWZTnFysgAVD1vh","timestamp":1600720882463}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JvkoC8rAYBE7","colab_type":"text"},"source":["\n","##Setup\n","\n","You will need to make a copy of this Colab notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**.\n"]},{"cell_type":"code","metadata":{"id":"-Q4lGYC_E6QQ","colab_type":"code","colab":{}},"source":["import os\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n","if not os.path.isdir('./omniglot_resized'):\n","    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n","                                        dest_path='./omniglot_resized.zip',\n","                                        unzip=True)\n","    \n","assert os.path.isdir('./omniglot_resized')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucYsULp9HUJy","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","from scipy import misc\n","\n","\n","def get_images(paths, labels, nb_samples=None, shuffle=True):\n","    \"\"\"\n","    Takes a set of character folders and labels and returns paths to image files\n","    paired with labels.\n","    Args:\n","        paths: A list of character folders\n","        labels: List or numpy array of same length as paths\n","        nb_samples: Number of images to retrieve per character\n","    Returns:\n","        List of (label, image_path) tuples\n","    \"\"\"\n","    if nb_samples is not None:\n","        sampler = lambda x: random.sample(x, nb_samples)\n","    else:\n","        sampler = lambda x: x\n","    images_labels = [(i, os.path.join(path, image))\n","                     for i, path in zip(labels, paths)\n","                     for image in sampler(os.listdir(path))]\n","    if shuffle:\n","        random.shuffle(images_labels)\n","    return images_labels\n","\n","\n","def image_file_to_array(filename, dim_input):\n","    \"\"\"\n","    Takes an image path and returns numpy array\n","    Args:\n","        filename: Image filename\n","        dim_input: Flattened shape of image\n","    Returns:\n","        1 channel image\n","    \"\"\"\n","    import imageio\n","    image = imageio.imread(filename)  # misc.imread(filename)\n","    image = image.reshape([dim_input])\n","    image = image.astype(np.float32) / 255.0\n","    image = 1.0 - image\n","    return image\n","\n","\n","class DataGenerator(object):\n","    \"\"\"\n","    Data Generator capable of generating batches of Omniglot data.\n","    A \"class\" is considered a class of omniglot digits.\n","    \"\"\"\n","\n","    def __init__(self, num_classes, num_samples_per_class, config={}):\n","        \"\"\"\n","        Args:\n","            num_classes: Number of classes for classification (K-way)\n","            num_samples_per_class: num samples to generate per class in one batch\n","            batch_size: size of meta batch size (e.g. number of functions)\n","        \"\"\"\n","        self.num_samples_per_class = num_samples_per_class\n","        self.num_classes = num_classes\n","\n","        data_folder = config.get('data_folder', './omniglot_resized')\n","        self.img_size = config.get('img_size', (28, 28))\n","\n","        self.dim_input = np.prod(self.img_size)\n","        self.dim_output = self.num_classes\n","\n","        character_folders = [os.path.join(data_folder, family, character)\n","                             for family in os.listdir(data_folder)\n","                             if os.path.isdir(os.path.join(data_folder, family))\n","                             for character in os.listdir(os.path.join(data_folder, family))\n","                             if os.path.isdir(os.path.join(data_folder, family, character))]\n","\n","        random.seed(1)\n","        random.shuffle(character_folders)\n","        num_val = 100\n","        num_train = 1100\n","        self.metatrain_character_folders = character_folders[: num_train]\n","        self.metaval_character_folders = character_folders[\n","            num_train:num_train + num_val]\n","        self.metatest_character_folders = character_folders[\n","            num_train + num_val:]\n","\n","    def sample_batch(self, batch_type, batch_size):\n","        \"\"\"\n","        Samples a batch for training, validation, or testing\n","        Args:\n","            batch_type: train/val/test\n","        Returns:\n","            A a tuple of (1) Image batch and (2) Label batch where\n","            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n","            where B is batch size, K is number of samples per class, N is number of classes\n","        \"\"\"\n","        if batch_type == \"train\":\n","            folders = self.metatrain_character_folders\n","        elif batch_type == \"val\":\n","            folders = self.metaval_character_folders\n","        else:\n","            folders = self.metatest_character_folders\n","\n","        #############################\n","        #### YOUR CODE GOES HERE ####\n","        pass\n","        #############################\n","\n","        return all_image_batches.astype(np.float32), all_label_batches.astype(np.float32)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yvqTOqTHVA9","colab_type":"code","colab":{}},"source":["import numpy as np\n","import random\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","\n","class MANN(tf.keras.Model):\n","\n","    def __init__(self, num_classes, samples_per_class):\n","        super(MANN, self).__init__()\n","        self.num_classes = num_classes\n","        self.samples_per_class = samples_per_class\n","        self.layer1 = tf.keras.layers.LSTM(128, return_sequences=True)\n","        self.layer2 = tf.keras.layers.LSTM(num_classes, return_sequences=True)\n","\n","    def call(self, input_images, input_labels):\n","        \"\"\"\n","        MANN\n","        Args:\n","            input_images: [B, K+1, N, 784] flattened images\n","            labels: [B, K+1, N, N] ground truth labels\n","        Returns:\n","            [B, K+1, N, N] predictions\n","        \"\"\"\n","        #############################\n","        #### YOUR CODE GOES HERE ####\n","        pass\n","        #############################\n","        return out\n","\n","    def loss_function(self, preds, labels):\n","        \"\"\"\n","        Computes MANN loss\n","        Args:\n","            preds: [B, K+1, N, N] network output\n","            labels: [B, K+1, N, N] labels\n","        Returns:\n","            scalar loss\n","        \"\"\"\n","        #############################\n","        #### YOUR CODE GOES HERE ####\n","        pass\n","        #############################\n","\n","\n","@tf.function\n","def train_step(images, labels, model, optim, eval=False):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images, labels)\n","        loss = model.loss_function(predictions, labels)\n","    if not eval:\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","        optim.apply_gradients(zip(gradients, model.trainable_variables))\n","    return predictions, loss\n","\n","\n","def main(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    tf.random.set_seed(random_seed)\n","\n","    data_generator = DataGenerator(num_classes, num_samples + 1)\n","\n","    o = MANN(num_classes, num_samples + 1)\n","    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","    for step in range(25000):\n","        i, l = data_generator.sample_batch('train', meta_batch_size)\n","        _, ls = train_step(i, l, o, optim)\n","\n","        if (step + 1) % 100 == 0:\n","            print(\"*\" * 5 + \"Iter \" + str(step + 1) + \"*\" * 5)\n","            i, l = data_generator.sample_batch('test', 100)\n","            pred, tls = train_step(i, l, o, optim, eval=True)\n","            print(\"Train Loss:\", ls.numpy(), \"Test Loss:\", tls.numpy())\n","            pred = tf.reshape(pred, [-1, num_samples + 1, num_classes, num_classes])\n","            pred = tf.math.argmax(pred[:, -1, :, :], axis=2)\n","            l = tf.math.argmax(l[:, -1, :, :], axis=2)\n","            print(\"Test Accuracy\", tf.reduce_mean(tf.cast(tf.math.equal(pred, l), tf.float32)).numpy())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"si10vH_0SH_y","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","results = main(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234)\n","#############################\n","#### YOUR CODE GOES HERE ####\n","# pass\n","#############################"],"execution_count":null,"outputs":[]}]}